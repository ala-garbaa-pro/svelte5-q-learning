[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

# Q-Learning Pathfinding Visualizer using Svelte5

An interactive visualization tool demonstrating the Q-Learning algorithm for pathfinding using SvelteKit and Canvas.

![Project Screenshot](screenshot.png)

##  Getting Started

1. Clone the repository:

```bash
git clone https://github.com/ala-garbaa-pro/svelte5-q-learning.git
cd svelte5-q-learning && code .
pnpm install
pnpm run dev
```

##  Overview

This project provides an intuitive and visual way to understand how Q-Learning, a fundamental reinforcement learning algorithm, works in the context of pathfinding. Users can watch the AI agent learn optimal paths between nodes in real-time with engaging visual and audio feedback.

## ‚ú® Features

-  Interactive graph visualization
-  Real-time learning process animation
-  Sound effects for enhanced user experience
-  Progress tracking and score system
- Ô∏è Multiple difficulty levels
-  Smooth animations and visual effects
-  Clean and modern UI using shadcn-svelte

## üõ†Ô∏è Technologies Used

[![SvelteKit](https://img.shields.io/badge/SvelteKit-FF3E00?style=for-the-badge&logo=svelte&logoColor=white)](https://kit.svelte.dev/)
[![TypeScript](https://img.shields.io/badge/TypeScript-007ACC?style=for-the-badge&logo=typescript&logoColor=white)](https://www.typescriptlang.org/)
[![Vite](https://img.shields.io/badge/Vite-646CFF?style=for-the-badge&logo=vite&logoColor=white)](https://vitejs.dev/)
[![Tailwind CSS](https://img.shields.io/badge/Tailwind_CSS-38B2AC?style=for-the-badge&logo=tailwind-css&logoColor=white)](https://tailwindcss.com/)
[![shadcn-svelte](https://img.shields.io/badge/shadcn--svelte-000000?style=for-the-badge&logo=svelte&logoColor=white)](https://www.shadcn-svelte.com/)

## üìñ Usage Guide

1. **Start the Application**
   - Run `pnpm run dev` to start the development server
   - Navigate to `http://localhost:5173` in your browser

2. **Using the Visualizer**
   - Click on the canvas to create nodes
   - Use the control panel to adjust learning parameters
   - Press "Start Learning" to begin the visualization
   - Watch as the agent learns optimal paths between nodes

3. **Adjusting Settings**
   - Learning Rate: Controls how quickly the agent learns
   - Exploration Rate: Determines random vs. learned actions
   - Speed: Adjust the animation speed
   - Sound: Toggle sound effects on/off

## ü§ù Contributing Guidelines

Contributions are always welcome! Here's how you can help:

1. Fork the repository
2. Create a new branch (`git checkout -b feature/improvement`)
3. Make your changes
4. Run tests if available
5. Commit your changes (`git commit -am 'Add new feature'`)
6. Push to the branch (`git push origin feature/improvement`)
7. Create a Pull Request

Please make sure to:
- Follow the existing code style
- Add comments for complex logic
- Update documentation as needed
- Test your changes thoroughly

## üôè Attribution

Made with ‚ù§Ô∏è by [Ala GARBAA](https://github.com/ala-garbaa-pro)

If you use this project, please provide attribution by linking back to this repository.

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.


MIT License
