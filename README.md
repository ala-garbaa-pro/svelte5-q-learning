[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

# Q-Learning Pathfinding Visualizer using Svelte5

An interactive visualization tool demonstrating the Q-Learning algorithm for pathfinding using SvelteKit and Canvas.

## ğŸ”¥ Live Demo

**[Try the Live Demo â†’](https://sv5ql.vercel.app/)**

![Project Screenshot](screenshot.png)

## ğŸš€ Quick Start

1. Clone the repository:

```bash
git clone https://github.com/ala-garbaa-pro/svelte5-q-learning.git
cd svelte5-q-learning && code .
pnpm install
pnpm run dev
```

## ğŸ¯ Overview

This project provides an intuitive and visual way to understand how Q-Learning, a fundamental reinforcement learning algorithm, works in the context of pathfinding. Users can watch the AI agent learn optimal paths between nodes in real-time with engaging visual and audio feedback.

## âœ¨ Key Features

- ğŸ® Interactive graph visualization
- âš¡ Real-time learning process animation
- ğŸ”Š Sound effects for enhanced user experience
- ğŸ“Š Progress tracking and score system
- ğŸšï¸ Multiple difficulty levels
- ğŸ¨ Smooth animations and visual effects
- ğŸ’… Clean and modern UI using shadcn-svelte

## ğŸ› ï¸ Tech Stack

[![SvelteKit](https://img.shields.io/badge/SvelteKit-FF3E00?style=for-the-badge&logo=svelte&logoColor=white)](https://kit.svelte.dev/)
[![TypeScript](https://img.shields.io/badge/TypeScript-007ACC?style=for-the-badge&logo=typescript&logoColor=white)](https://www.typescriptlang.org/)
[![Vite](https://img.shields.io/badge/Vite-646CFF?style=for-the-badge&logo=vite&logoColor=white)](https://vitejs.dev/)
[![Tailwind CSS](https://img.shields.io/badge/Tailwind_CSS-38B2AC?style=for-the-badge&logo=tailwind-css&logoColor=white)](https://tailwindcss.com/)
[![shadcn-svelte](https://img.shields.io/badge/shadcn--svelte-000000?style=for-the-badge&logo=svelte&logoColor=white)](https://www.shadcn-svelte.com/)

## ğŸ“– How to Use

### 1. Starting the Application
- Run `pnpm run dev`
- Visit `http://localhost:5173` in your browser

### 2. Using the Visualizer
- Click on the canvas to create nodes
- Use the control panel to adjust learning parameters
- Press "Start Learning" to begin the visualization
- Watch as the agent learns optimal paths between nodes

### 3. Adjusting Settings
- Learning Rate: Controls how quickly the agent learns
- Exploration Rate: Determines random vs. learned actions
- Speed: Adjust the animation speed
- Sound: Toggle sound effects on/off

## ğŸ¤ How to Contribute

We welcome contributions! Here's how:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/improvement`)
3. Make your changes
4. Run tests if available
5. Commit changes (`git commit -am 'Add new feature'`)
6. Push to branch (`git push origin feature/improvement`)
7. Open a Pull Request

**Please ensure you:**
- Follow existing code style
- Add comments for complex logic
- Update documentation
- Test thoroughly

## ğŸ™ Attribution

Made with â¤ï¸ by [Ala GARBAA](https://github.com/ala-garbaa-pro)

If you use this project, please provide attribution by linking back to this repository.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.


MIT License
